{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # old logging\n",
        "# from applicationinsights import TelemetryClient  \n",
        "# from applicationinsights.logging import enable\n",
        "# import os\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv(\"credentials.env\")\n",
        "\n",
        "# instrumentation_key = os.environ.get(\"APPLICATION_INSIGHTS_INSTRUMENTATION_KEY\"  )\n",
        "# client = TelemetryClient(instrumentation_key)  \n",
        "# enable(instrumentation_key)  \n",
        "\n",
        "# event_properties = {  \n",
        "#     'property1': 'value1',  \n",
        "#     'property2': 'value2'  \n",
        "# }  \n",
        "# client.track_event('LanguageModelResult', event_properties)  \n",
        "# client.flush()  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1702474459841
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.agents import ConversationalChatAgent, AgentExecutor, Tool\n",
        "from langchain.memory import CosmosDBChatMessageHistory\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "\n",
        "from azure.monitor.events.extension import track_event\n",
        "from azure.monitor.opentelemetry import configure_azure_monitor\n",
        "\n",
        "#custom libraries that we will use later in the app\n",
        "from common.utils_povel import DocSearchTool, CSVTabularTool, SQLDbTool, ChatGPTTool, BingSearchTool, run_agent, get_search_results\n",
        "from common.callbacks import StdOutCallbackHandler\n",
        "from common.prompts_povel import CUSTOM_CHATBOT_PREFIX, CUSTOM_CHATBOT_SUFFIX \n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "from IPython.display import Markdown, HTML, display \n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "MODEL_DEPLOYMENT_NAME = \"gpt-4-32k\" # Reminder: gpt-35-turbo models will create parsing errors and won't follow instructions correctly \n",
        "# MODEL_DEPLOYMENT_NAME = \"gpt-35-turbo-16k\" # Reminder: gpt-35-turbo models will create parsing errors and won't follow instructions correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1702474461535
        }
      },
      "outputs": [],
      "source": [
        "configure_azure_monitor(disable_metric=True, connection_string=os.environ.get(\"APPLICATION_INSIGHTS_CONNECTION_STRING\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1702474462018
        }
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1702474462999
        }
      },
      "outputs": [],
      "source": [
        "cb_handler = StdOutCallbackHandler()\n",
        "cb_manager = CallbackManager(handlers=[cb_handler])\n",
        "\n",
        "llm = AzureChatOpenAI(deployment_name=MODEL_DEPLOYMENT_NAME, temperature=0.2, max_tokens=800)\n",
        "\n",
        "# Uncomment the below line if you want to see the responses being streamed/typed\n",
        "# llm = AzureChatOpenAI(deployment_name=MODEL_DEPLOYMENT_NAME, temperature=0.5, max_tokens=500, streaming=True, callback_manager=cb_manager)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1702474466123
        }
      },
      "outputs": [],
      "source": [
        "vector_only_indexes = [\"digge-ekonomi-index-files-on-your-data\"] # funkar bättre på fråga : \"@docsearch, Vilket konto ska jag fakturera egenavgift för hjälpmedel?\"\n",
        "# vector_only_indexes = [\"1b-digge-100-full\", \"1b-digge-ekonomi-full\"]\n",
        "# vector_only_indexes = [\"1b-digge-100-full\", \"digge-ekonomi-index-files-on-your-data\"]\n",
        "\n",
        "doc_search = DocSearchTool(\n",
        "    llm=llm,\n",
        "    vector_only_indexes=vector_only_indexes,\n",
        "    k=10,\n",
        "    similarity_k=20,\n",
        "    reranker_th=1,\n",
        "    sas_token=os.environ[\"BLOB_SAS_TOKEN\"],\n",
        "    callback_manager=cb_manager,\n",
        "    return_direct=True,\n",
        "    # This is how you can edit the default values of name and description\n",
        "    name=\"@docsearch\",\n",
        "    description=\"useful when the questions includes the term: @docsearch.\\n\",\n",
        ")\n",
        "\n",
        "# SQLDbTool is a custom Tool class created to Q&A over a MS SQL Database\n",
        "sql_search = SQLDbTool(llm=llm, k=30, callback_manager=cb_manager, return_direct=True)\n",
        "\n",
        "# ChatGPTTool is a custom Tool class created to talk to ChatGPT knowledge\n",
        "chatgpt_search = ChatGPTTool(llm=llm, callback_manager=cb_manager, return_direct=True)\n",
        "\n",
        "# BingSearchTool is a langchain Tool class to use the Bing Search API (https://www.microsoft.com/en-us/bing/apis/bing-web-search-api)\n",
        "www_search = BingSearchTool(llm=llm, k=5, callback_manager=cb_manager, return_direct=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1702474468247
        }
      },
      "outputs": [],
      "source": [
        "tools = [www_search, sql_search, doc_search, chatgpt_search]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1702474469178
        }
      },
      "outputs": [],
      "source": [
        "cosmos = CosmosDBChatMessageHistory(\n",
        "    cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
        "    cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
        "    cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
        "    connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
        "    session_id=\"Agent-Test-Session\" + str(random.randint(1, 1000)),\n",
        "    user_id=\"Agent-Test-User\" + str(random.randint(1, 1000))\n",
        "    )\n",
        "# prepare the cosmosdb instance\n",
        "cosmos.prepare_cosmos()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1702474474277
        }
      },
      "outputs": [],
      "source": [
        "llm_a = AzureChatOpenAI(deployment_name=MODEL_DEPLOYMENT_NAME, temperature=0.2, max_tokens=500)\n",
        "agent = ConversationalChatAgent.from_llm_and_tools(llm=llm_a, tools=tools, system_message=CUSTOM_CHATBOT_PREFIX, human_message=CUSTOM_CHATBOT_SUFFIX)\n",
        "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", return_messages=True, k=10, chat_memory=cosmos)\n",
        "agent_chain = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, memory=memory, handle_parsing_errors=True)\n",
        "\n",
        "# # Let's see the custom prompt prefix we created for our brain agent\n",
        "# printmd(agent_chain.agent.llm_chain.prompt.messages[0].prompt.template)\n",
        "\n",
        "# # Also let's see the Prompt that the Agent uses to talk to the LLM\n",
        "# printmd(agent_chain.agent.llm_chain.prompt.messages[2].prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tool: @docsearch\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Du bör fakturera egenavgift för hjälpmedel på konto 3083<sup><a href=\"https://blobstoragejd5ypzfx2l6vi.blob.core.windows.net/digge-ekonomi-dokument/Artikelf%C3%B6rteckning%20f%C3%B6r%20Agresso%20weborder.pdf\" target=\"_blank\">[1]</a></sup>."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "QUESTION = \"@docsearch, Vilket konto ska jag fakturera egenavgift för hjälpmedel?\"\n",
        "response = run_agent(QUESTION, agent_chain)\n",
        "printmd(response)\n",
        "\n",
        "track_event(\"LanguageModelResult\",\n",
        "            {\n",
        "                \"Prompt\": QUESTION, #User input text\n",
        "                \"Completion\": response, # AI-generated text\n",
        "            })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tool: @docsearch\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Ingående moms fungerar genom att företag kan dra av momsen på inköp av varor och tjänster som används i verksamheten. Om kostnaden för förtäring per person överstiger 300 kr exklusive moms, kan hela den ingående momsen dras av. Om kostnaden överstiger 300 kr exklusive moms per person och förtäringstillfälle, begränsas avdraget till den ingående momsen som beräknas på beloppet 300 kr exklusive moms. För andra kostnader, som entréavgifter till evenemang, kan avdrag göras med momsen på ett underlag om 180 kronor exklusive moms. Vid inköp av varor från EU-land kan försäljning utan moms göras om köparen är momsregistrerad i ett annat EU-land och köparens VAT-nummer anges på fakturan. Vid försäljning utanför EU räknas det som export och ingen moms tillkommer. För mer information och detaljerade regler kan man besöka Skatteverkets hemsida<sup><a href=\"https://www.skatteverket.se/\" target=\"_blank\">[1]</a></sup><sup><a href=\"https://ec.europa.eu/taxation_customs/vies/#/vat-validation\" target=\"_blank\">[2]</a></sup>.\n",
              "\n",
              "References:\n",
              "[1] <a href=\"https://blobstoragejd5ypzfx2l6vi.blob.core.windows.net/digge-ekonomi-dokument/Momsguiden.pdf\" target=\"_blank\">[1]</a>\n",
              "[2] <a href=\"https://blobstoragejd5ypzfx2l6vi.blob.core.windows.net/digge-ekonomi-dokument/Kontoplan.pdf\" target=\"_blank\">[2]</a>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Bad pipe message: %s [b\"n'\\x8bR\\xaf\\xad\\xbd\\xc1u\\xebuO\\x0b4\\xeb\\xb9\\xdf\\xa5\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0\", b\"$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\"]\n",
            "Bad pipe message: %s [b'\\xaa\\xb9D>\\x92e\\rKn\\x1ds\\xc5\\x05\\xf0i\\xe7\\x13\\xf9\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05']\n",
            "Bad pipe message: %s [b\"\\xc8k\\x0e\\xeb\\x1d<\\xbb.H\\xef\\xd3.\\x8a\\xd9\\x04\\xb3)t\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\r\\x00 \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05\\x02\\x05\\x03\\x04\\x01\\x04\\x02\\x04\\x03\\x03\\x01\\x03\"]\n",
            "Bad pipe message: %s [b'\\x03', b'\\x02', b'\\x03']\n",
            "Bad pipe message: %s [b'7F&\\xeb\\xc9Am\\\\\\x89Y\\xbeS\\xa2\\xae\\xf4A\\xe2\\xc7\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j']\n"
          ]
        }
      ],
      "source": [
        "QUESTION = \"@docsearch, Hur fungerar ingående moms?\"\n",
        "response = run_agent(QUESTION, agent_chain)\n",
        "printmd(response)\n",
        "\n",
        "track_event(\"LanguageModelResult\",\n",
        "            {\n",
        "                \"Prompt\": QUESTION, #User input text\n",
        "                \"Completion\": response, # AI-generated text\n",
        "            })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1702474534002
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tool: @sqlsearch\n",
            "Action: sql_db_list_tables\n",
            "Action Input: \"\"\n",
            "The database contains a table named \"covidtracking\". This table might contain the data needed to answer the question. I should check the schema of this table to confirm.\n",
            "Action: sql_db_schema\n",
            "Action Input: \"covidtracking\"\n",
            "The \"covidtracking\" table has the columns \"state\", \"date\", and \"hospitalizedIncrease\" which are relevant to the question. I can use these columns to construct a query that will return the total number of people hospitalized in Texas and all states in July 2020.\n",
            "Action: sql_db_query_checker\n",
            "Action Input: \"SELECT state, SUM(hospitalizedIncrease) as TotalHospitalized FROM covidtracking WHERE date BETWEEN '2020-07-01' AND '2020-07-31' GROUP BY state HAVING state='TX' OR state='ALL'\"\n",
            "The SQL query syntax is correct. I can now run this query to get the total number of people hospitalized in Texas and all states in July 2020.\n",
            "Action: sql_db_query\n",
            "Action Input: \"SELECT state, SUM(hospitalizedIncrease) as TotalHospitalized FROM covidtracking WHERE date BETWEEN '2020-07-01' AND '2020-07-31' GROUP BY state HAVING state='TX' OR state='ALL'\"\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "In July 2020, there were no new hospitalizations recorded in Texas.\n",
              "\n",
              "Explanation:\n",
              "I queried the `covidtracking` table for the sum of the `hospitalizedIncrease` column where the state is 'TX' and the date is between '2020-07-01' and '2020-07-31'. The query returned a list of tuples with the state and the total number of new hospitalizations for that state in July 2020. To answer the question, I looked at the tuple for Texas, which shows that there were no new hospitalizations recorded in Texas in July 2020. \n",
              "I used the following query\n",
              "\n",
              "```sql\n",
              "SELECT state, SUM(hospitalizedIncrease) as TotalHospitalized \n",
              "FROM covidtracking \n",
              "WHERE date BETWEEN '2020-07-01' AND '2020-07-31' \n",
              "GROUP BY state \n",
              "HAVING state='TX' OR state='ALL'\n",
              "```"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from azure.monitor.events.extension import track_event\n",
        "# from azure.monitor.opentelemetry import configure_azure_monitor\n",
        "\n",
        "# configure_azure_monitor(disable_metric=True, connection_string=os.environ.get(\"APPLICATION_INSIGHTS_CONNECTION_STRING\"))\n",
        "\n",
        "# QUESTION = \"@sqlsearch, How many people died of covid in Texas in 2020?\"\n",
        "QUESTION = \"@sqlsearch, How may patients were hospitalized during July 2020 in Texas, and nationwide as the total of all states? Use the hospitalizedIncrease column?\"\n",
        "\n",
        "response=run_agent(QUESTION, agent_chain)\n",
        "printmd(response)\n",
        "\n",
        "track_event(\"LanguageModelResult\",\n",
        "            {\n",
        "                \"Prompt\": QUESTION, #User input text\n",
        "                \"Completion\": response, # AI-generated text\n",
        "            })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "QUESTION = \"@bing, I need to take my girlfriend to dinner tonight in downtown Chicago. Please give me options for Italian and Sushi as well\"\n",
        "response=run_agent(QUESTION, agent_chain)\n",
        "printmd(response)\n",
        "\n",
        "track_event(\"LanguageModelResult\",\n",
        "            {\n",
        "                \"Prompt\": QUESTION, #User input text\n",
        "                \"Completion\": response, # AI-generated text\n",
        "            })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "QUESTION = \"\"\"\n",
        "compare the number of job opennings (provide the exact number), the average salary within 15 miles of Dallas, TX, for these ocupations:\n",
        "\n",
        "- ADN Registerd Nurse \n",
        "- Occupational therapist assistant\n",
        "- Dental Hygienist\n",
        "- Graphic Designer\n",
        "- Real Estate Agent\n",
        "\n",
        "Create a table with your findings. Place the sources on each cell.\n",
        "\"\"\"\n",
        "response=run_agent(QUESTION, agent_chain)\n",
        "printmd(response)\n",
        "\n",
        "track_event(\"LanguageModelResult\",\n",
        "            {\n",
        "                \"Prompt\": QUESTION, #User input text\n",
        "                \"Completion\": response, # AI-generated text\n",
        "            })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "QUESTION = \"@chatgpt, tell me the formula in physics for momentum\"\n",
        "response=run_agent(QUESTION, agent_chain)\n",
        "printmd(response)\n",
        "\n",
        "track_event(\"LanguageModelResult\",\n",
        "            {\n",
        "                \"Prompt\": QUESTION, #User input text\n",
        "                \"Completion\": response, # AI-generated text\n",
        "            })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
