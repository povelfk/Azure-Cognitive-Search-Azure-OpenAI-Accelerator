{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old logging\n",
    "# from applicationinsights import TelemetryClient  \n",
    "# from applicationinsights.logging import enable\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(\"credentials.env\")\n",
    "\n",
    "# instrumentation_key = os.environ.get(\"APPLICATION_INSIGHTS_INSTRUMENTATION_KEY\"  )\n",
    "# client = TelemetryClient(instrumentation_key)  \n",
    "# enable(instrumentation_key)  \n",
    "\n",
    "# event_properties = {  \n",
    "#     'property1': 'value1',  \n",
    "#     'property2': 'value2'  \n",
    "# }  \n",
    "# client.track_event('LanguageModelResult', event_properties)  \n",
    "# client.flush()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.agents import ConversationalChatAgent, AgentExecutor, Tool\n",
    "from langchain.memory import CosmosDBChatMessageHistory\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "\n",
    "from azure.monitor.events.extension import track_event\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "\n",
    "#custom libraries that we will use later in the app\n",
    "from common.utils_povel import DocSearchTool, CSVTabularTool, SQLDbTool, ChatGPTTool, BingSearchTool, run_agent, get_search_results\n",
    "from common.callbacks import StdOutCallbackHandler\n",
    "from common.prompts_povel import CUSTOM_CHATBOT_PREFIX, CUSTOM_CHATBOT_SUFFIX \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "from IPython.display import Markdown, HTML, display \n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "MODEL_DEPLOYMENT_NAME = \"gpt-4-32k\" # Reminder: gpt-35-turbo models will create parsing errors and won't follow instructions correctly \n",
    "# MODEL_DEPLOYMENT_NAME = \"gpt-35-turbo-16k\" # Reminder: gpt-35-turbo models will create parsing errors and won't follow instructions correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_azure_monitor(disable_metric=True, connection_string=os.environ.get(\"APPLICATION_INSIGHTS_CONNECTION_STRING\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_handler = StdOutCallbackHandler()\n",
    "cb_manager = CallbackManager(handlers=[cb_handler])\n",
    "\n",
    "llm = AzureChatOpenAI(deployment_name=MODEL_DEPLOYMENT_NAME, temperature=0.2, max_tokens=800)\n",
    "\n",
    "# Uncomment the below line if you want to see the responses being streamed/typed\n",
    "# llm = AzureChatOpenAI(deployment_name=MODEL_DEPLOYMENT_NAME, temperature=0.5, max_tokens=500, streaming=True, callback_manager=cb_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_only_indexes = [\"digge-ekonomi-index-files-on-your-data\"] # funkar bättre på fråga : \"@docsearch, Vilket konto ska jag fakturera egenavgift för hjälpmedel?\"\n",
    "vector_only_indexes = [\"1b-digge-100-full\", \"1b-digge-ekonomi-full\"]\n",
    "\n",
    "doc_search = DocSearchTool(\n",
    "    llm=llm,\n",
    "    vector_only_indexes=vector_only_indexes,\n",
    "    k=10,\n",
    "    similarity_k=5,\n",
    "    reranker_th=1,\n",
    "    sas_token=os.environ[\"BLOB_SAS_TOKEN\"],\n",
    "    callback_manager=cb_manager,\n",
    "    return_direct=True,\n",
    "    # This is how you can edit the default values of name and description\n",
    "    name=\"@docsearch\",\n",
    "    description=\"useful when the questions includes the term: @docsearch.\\n\",\n",
    ")\n",
    "\n",
    "# SQLDbTool is a custom Tool class created to Q&A over a MS SQL Database\n",
    "sql_search = SQLDbTool(llm=llm, k=30, callback_manager=cb_manager, return_direct=True)\n",
    "\n",
    "# ChatGPTTool is a custom Tool class created to talk to ChatGPT knowledge\n",
    "chatgpt_search = ChatGPTTool(llm=llm, callback_manager=cb_manager, return_direct=True)\n",
    "\n",
    "# BingSearchTool is a langchain Tool class to use the Bing Search API (https://www.microsoft.com/en-us/bing/apis/bing-web-search-api)\n",
    "www_search = BingSearchTool(llm=llm, k=5, callback_manager=cb_manager, return_direct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [www_search, sql_search, doc_search, chatgpt_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmos = CosmosDBChatMessageHistory(\n",
    "    cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
    "    cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
    "    cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
    "    connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
    "    session_id=\"Agent-Test-Session\" + str(random.randint(1, 1000)),\n",
    "    user_id=\"Agent-Test-User\" + str(random.randint(1, 1000))\n",
    "    )\n",
    "# prepare the cosmosdb instance\n",
    "cosmos.prepare_cosmos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_a = AzureChatOpenAI(deployment_name=MODEL_DEPLOYMENT_NAME, temperature=0.2, max_tokens=500)\n",
    "agent = ConversationalChatAgent.from_llm_and_tools(llm=llm_a, tools=tools, system_message=CUSTOM_CHATBOT_PREFIX, human_message=CUSTOM_CHATBOT_SUFFIX)\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", return_messages=True, k=10, chat_memory=cosmos)\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, memory=memory, handle_parsing_errors=True)\n",
    "\n",
    "# # Let's see the custom prompt prefix we created for our brain agent\n",
    "# printmd(agent_chain.agent.llm_chain.prompt.messages[0].prompt.template)\n",
    "\n",
    "# # Also let's see the Prompt that the Agent uses to talk to the LLM\n",
    "# printmd(agent_chain.agent.llm_chain.prompt.messages[2].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: @docsearch\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Du bör fakturera egenavgift för hjälpmedel på konto 3083<sup><a href=\"https://blobstoragejd5ypzfx2l6vi.blob.core.windows.net/digge-ekonomi-dokument/Artikelf%C3%B6rteckning%20f%C3%B6r%20Agresso%20weborder.pdf\" target=\"_blank\">[1]</a></sup>."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "QUESTION = \"@docsearch, Vilket konto ska jag fakturera egenavgift för hjälpmedel?\"\n",
    "response = run_agent(QUESTION, agent_chain)\n",
    "printmd(response)\n",
    "\n",
    "track_event(\"LanguageModelResult\",\n",
    "            {\n",
    "                \"Prompt\": QUESTION, #User input text\n",
    "                \"Completion\": response, # AI-generated text\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: @docsearch\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Ingående moms fungerar på följande sätt: När man köper varor och tjänster till verksamheten kan man dra av den ingående momsen. Om kostnaden för förtäring per person överstiger 300 kr exklusive moms, kan hela den ingående momsen dras av. Om kostnaden överstiger 300 kr exklusive moms per person, begränsas avdraget till den ingående momsen som beräknas på beloppet 300 kr exklusive moms. För andra kostnader, som entréavgifter till konserter eller liknande, får avdrag göras med momsen på ett underlag om 180 kronor exklusive moms. Vid försäljning av varor inom EU kan försäljning utan moms göras om köparen är momsregistrerad i ett annat EU-land och köparens VAT-nummer anges på fakturan. Vid försäljning utanför EU räknas det som export och ingen moms tillkommer. För mer information och exempel, se Momsguiden<sup><a href=\"https://blobstoragejd5ypzfx2l6vi.blob.core.windows.net/digge-ekonomi-dokument/Momsguiden.pdf\" target=\"_blank\">[1]</a></sup> och Kontoplan<sup><a href=\"https://blobstoragejd5ypzfx2l6vi.blob.core.windows.net/digge-ekonomi-dokument/Kontoplan.pdf\" target=\"_blank\">[2]</a></sup>."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "QUESTION = \"@docsearch, Hur fungerar ingående moms?\"\n",
    "response = run_agent(QUESTION, agent_chain)\n",
    "printmd(response)\n",
    "\n",
    "track_event(\"LanguageModelResult\",\n",
    "            {\n",
    "                \"Prompt\": QUESTION, #User input text\n",
    "                \"Completion\": response, # AI-generated text\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION = \"@sqlsearch, How many people died of covid in Texas in 2020?\"\n",
    "QUESTION = \"@sqlsearch, How may patients were hospitalized during July 2020 in Texas, and nationwide as the total of all states? Use the hospitalizedIncrease column?\"\n",
    "\n",
    "response=run_agent(QUESTION, agent_chain)\n",
    "printmd(response)\n",
    "\n",
    "track_event(\"LanguageModelResult\",\n",
    "            {\n",
    "                \"Prompt\": QUESTION, #User input text\n",
    "                \"Completion\": response, # AI-generated text\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"@bing, I need to take my girlfriend to dinner tonight in downtown Chicago. Please give me options for Italian and Sushi as well\"\n",
    "response=run_agent(QUESTION, agent_chain)\n",
    "printmd(response)\n",
    "\n",
    "track_event(\"LanguageModelResult\",\n",
    "            {\n",
    "                \"Prompt\": QUESTION, #User input text\n",
    "                \"Completion\": response, # AI-generated text\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"\"\"\n",
    "compare the number of job opennings (provide the exact number), the average salary within 15 miles of Dallas, TX, for these ocupations:\n",
    "\n",
    "- ADN Registerd Nurse \n",
    "- Occupational therapist assistant\n",
    "- Dental Hygienist\n",
    "- Graphic Designer\n",
    "- Real Estate Agent\n",
    "\n",
    "Create a table with your findings. Place the sources on each cell.\n",
    "\"\"\"\n",
    "response=run_agent(QUESTION, agent_chain)\n",
    "printmd(response)\n",
    "\n",
    "track_event(\"LanguageModelResult\",\n",
    "            {\n",
    "                \"Prompt\": QUESTION, #User input text\n",
    "                \"Completion\": response, # AI-generated text\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"@chatgpt, tell me the formula in physics for momentum\"\n",
    "response=run_agent(QUESTION, agent_chain)\n",
    "printmd(response)\n",
    "\n",
    "track_event(\"LanguageModelResult\",\n",
    "            {\n",
    "                \"Prompt\": QUESTION, #User input text\n",
    "                \"Completion\": response, # AI-generated text\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
